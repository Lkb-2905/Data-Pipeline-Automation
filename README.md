ğŸŒ DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# âš¡ DPA : Data Pipeline Automation
![Python](https://img.shields.io/badge/Python-3.12-blue) ![SQLite](https://img.shields.io/badge/SQLite-Data_Warehouse-lightgrey) ![Pandas](https://img.shields.io/badge/Pandas-Transformation-green)

**Version:** 1.0.0 Stable | **Date:** FÃ©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

ğŸš€ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ ğŸ“š [Documentation](#-guide-dutilisation) â€¢ ğŸ¯ [FonctionnalitÃ©s](#-fonctionnalitÃ©s-clÃ©s) â€¢ ğŸ”§ [Installation](#-installation-rapide)

---

## ğŸ“‹ TABLE DES MATIÃˆRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#ï¸-architecture-technique)
3. [Stack Technologique](#ï¸-stack-technologique)
4. [FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
5. [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
6. [Guide d'Utilisation](#-guide-dutilisation)
7. [QualitÃ© & Best Practices](#-qualitÃ©--best-practices)
8. [Roadmap & Ã‰volutions](#ï¸-roadmap--Ã©volutions)

---

## ğŸ¯ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet illustre l'implÃ©mentation robuste d'une architecture **Data-Driven (ETL)** pour le pilotage logistique des donnÃ©es de fret. Il rÃ©pond aux exigences d'une gouvernance informatique moderne en unifiant les donnÃ©es, les fichiers Ã©pars et les signaux mÃ©tiers.

Il illustre les compÃ©tences suivantes :

âœ… **Architecture DÃ©couplÃ©e :** SÃ©paration stricte Extract / Transform / Load.
âœ… **Data Warehouse IntÃ©grÃ© :** Consolidation transactionnelle au sein d'une BDD relationnelle.
âœ… **Scripts D'Orchestration :** Conception d'opÃ©rations cycliques pour le chargement massif.
âœ… **Performance Data :** Manipulation vectorielle pour nettoyage rapide.
âœ… **Industrialisation :** Plan de ContinuitÃ© (PCR) et documentation de rigueur technologique (DCE).
âœ… **Clean Code :** Respect des standards (ModularitÃ© pure Python, SGBD).

### Pourquoi ce projet ?
| Aspect | DÃ©monstration |
| --- | --- |
| **ScalabilitÃ©** | Le Pipeline asynchrone est prÃªt Ã  recevoir d'Ã©normes volumes. |
| **MaintenabilitÃ©** | Code modulaire sÃ©parant les responsabilitÃ©s Extraction et Nettoyage. |
| **Innovation** | Automatisation intÃ©grale du cycle de vie de l'information brute Ã©tudiÃ©e. |
| **SÃ©curitÃ©** | Transaction ACID sÃ©curisÃ©es (Rollback sur Ã©chec SGBD). |
| **Business Value** | Dote les gestionnaires de KPI calculÃ©s et requÃªtes avancÃ©es (Data Warehouse). |

---

## ğŸ—ï¸ ARCHITECTURE TECHNIQUE

### Diagramme de Flux
```mermaid
graph TD
    subgraph Client Layer
        U[ğŸ‘¤ DÃ©cideur Supply Chain]
        P[DBeaver / Dashboard BI]
        U -->|Pilotage| P
    end

    subgraph Application Layer
        E[Extracteur API JSON]
        T[Transformateur Pandas]
        L[Chargeur SQLAlchemy]
        E -->|Nettoyage| T
        T -->|Manipulation| L
    end

    subgraph Data Sources
        S[Terminaux Logistiques Fret]
    end

    subgraph Database Layer
        D[(Data Warehouse<br>SQLite)]
    end

    S -->|Sources JSON| E
    L -->|Upsert SQL| D
    D -->|RequÃªtes Analytiques| P

    style P fill:#4FC3F7,color:#000
    style E fill:#4CAF50,color:#fff
    style T fill:#4CAF50,color:#fff
    style L fill:#4CAF50,color:#fff
    style D fill:#FFD600,color:#000
    style S fill:#FF5252,color:#fff
```

### Flux de DonnÃ©es DÃ©taillÃ©
1. **Extraction de DonnÃ©es** : Simule un appel d'API aux terminaux logistiques et rapatrie les relevÃ©s journaliers (`extract.py`).
2. **Transformation des Champs** : Fusionne les tables temporelles via Python Pandas pour assurer la cohÃ©rence (`transform.py`).
3. **Chargement SQL (Load)** : InsÃ¨re massivement et de maniÃ¨re transactionnelle les donnÃ©es dans `supply_chain_dwh.sqlite`.
4. **AggrÃ©gation & Restitution** : RequÃªtes analytiques pour des tableaux dÃ©cisionnels avec fonctionnalitÃ©s `LAG()` et Window Functions.

---

## ğŸ› ï¸ STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Orchestrateur** | Python | 3.12+ | L'outil complet de traitement universel par batch d'ingÃ©nierie. |
| **Base de DonnÃ©es** | SQLite | 3+ | DWH de fichier ultra-lÃ©ger et transportable localement. |
| **Data Engine** | Pandas | Latest | Traitement et jointure rapide de la donnÃ©e en RAM. |
| **ORM et Mapping** | SQLAlchemy | Latest | ConnectivitÃ© et sÃ©curitÃ© des transactions SQL (pas de SQL syntax direct en paramÃ¨tre mÃ©tier). |

### BibliothÃ¨ques ComplÃ©mentaires
* **Loguru/Logging :** TraÃ§abilitÃ© exhaustive.
* **OS/Sys :** Commandes natives utiles Ã  l'interaction Windows (Task Scheduler).

---

## ğŸ¯ FONCTIONNALITÃ‰S CLÃ‰S

### ğŸš€ FonctionnalitÃ©s Principales
**Gouvernance Data Temps RÃ©el**
* Consolidations des flux Ã©pars vers une Base Unique.
* CrÃ©ation propre et persistante de `supply_chain_dwh.sqlite`.

**SystÃ¨me AvancÃ© de RequÃªtage**
* DÃ©ploiement de scripts SQL analytiques poussÃ©s pour catÃ©goriser la fiabilitÃ© du systÃ¨me (Hub Logistics Classification).

**Gestion des Risques**
* TolÃ©rance du Pipeline en mode fail-safe sur corruption partielle de fichier.

### ğŸ›¡ï¸ SÃ©curitÃ© & Robustesse
| Aspect | ImplÃ©mentation |
| --- | --- |
| **Validation** | VÃ©rification et parsing stricts avant transaction. |
| **RÃ©silience** | Base de donnÃ©es SQL protÃ©gÃ©e des deadlocks et Ã©checs (Rollbacks). |
| **TraÃ§abilitÃ©** | Logs dÃ©taillÃ©s sur serveurs ou scripts chronologiques. |

---

## ğŸš€ DÃ‰MARRAGE RAPIDE

### PrÃ©requis
* Python (v3.12+)

### Installation Rapide
```bash
# 1. Cloner le projet (Naviguer au sein du rÃ©pertoire)
cd Data-Pipeline-Automation

# 2. Installer les dÃ©pendances (crÃ©er l'environnement virtuel)
python -m venv env
.\env\Scripts\activate
pip install -r requirements.txt

# 3. Lancer l'Orchestrateur Complet
python src/main_pipeline.py
```
**AccÃ¨s ImmÃ©diat :** Les tables historiques sont fraÃ®ches et disponibles instantanÃ©ment dans `database/supply_chain_dwh.sqlite`.

---

## ğŸ“– GUIDE D'UTILISATION

### ScÃ©nario de Pilotage
1. **Lancement Quotidien :** L'outil tourne la nuit via scheduler.
2. **RequÃªtage Expert :** Un Data Analyst peut soumettre `sql/advanced_queries.sql` au DBeaver de la base.
3. **Action:** Construction de Dashboard et exports mÃ©tier sur l'activitÃ© des "Gares".

### Captures d'Ã‰cran
**ğŸ“¸ Validation ETL Backend**  
![ExÃ©cution du Pipeline ETL](execution_screenshot.png)

---

## âœ¨ QUALITÃ‰ & BEST PRACTICES

### Standards de Code
* **ModularitÃ© (Engine) :** Couches E, T, et L isolÃ©es nativement.
* **Typage (Data) :** Cast structurÃ©s au sein des Dataframes.
* **Error Handling :** Blocs robustes limitant l'Ã©crasement bdd en cas de corruption.

### MÃ©triques d'Excellence
âœ… **Architecture :** DWH Single Source of Truth respectÃ© (SSOT).
âœ… **Performance :** L'ORM insÃ¨re des dizaines de milliers de lignes en lots optimisÃ©s (bulk).

---

## ğŸ—ºï¸ ROADMAP & Ã‰VOLUTIONS

**Version Actuelle : 1.0.0 âœ…**
* Architecture complÃ¨te et Pipeline de Chargement abouti.
* ExÃ©cution orientÃ©e SGBD local pour prototypage rapide.
* Documentation exhaustive DCE.

**Version 2.1.0 (Prochaine Release) ğŸš§**
* Virtualisation Globale : Orchestration via Docker Compose / Airflow.
* Base de DonnÃ©es : Connecteur vers Cloud Azure SQL / PostgreSQL Serveur lourd.

---

## ğŸ¤ CONTRIBUTION
Les contributions sont les bienvenues pour industrialiser ce socle mÃ©tier logistique.
1. Forker.
2. DÃ©finir une Feature Branche.
3. Valider par PR documentÃ©e.

---

## ğŸ“„ LICENCE
Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique et professionnel. Droits rÃ©servÃ©s.

## ğŸ‘¨â€ğŸ’» AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
IngÃ©nieur Logiciel & Data Scientist en devenir | Ã‰tudiant ESIEA  

ğŸ“§ Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
ğŸ™ GitHub : @Lkb-2905  

ğŸ™ **REMERCIEMENTS**
* **TotalEnergies / BollorÃ© :** Pour l'approche industrielle robuste Data Management.
* **ESIEA :** Pour l'excellence informatique et acadÃ©mique.

â­ Si ce projet vous semble pertinent pour la Supply Chain de demain, laissez une Ã©toile !  
Fait avec â¤ï¸, Python et du SQL.  

Â© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits rÃ©servÃ©s
