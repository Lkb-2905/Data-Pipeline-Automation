üåç DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
üåç Supply Chain Data Pipeline V1.0
![Python](https://img.shields.io/badge/Python-3.12-blue) ![SQLite](https://img.shields.io/badge/SQLite-Data_Warehouse-lightgrey) ![Pandas](https://img.shields.io/badge/Pandas-ETL-purple) ![PowerShell](https://img.shields.io/badge/PowerShell-Automation-blue)

**Version:** 1.0.0 Stable | **Date:** F√©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr

üöÄ [D√©marrage Rapide](#-d√©marrage-rapide) ‚Ä¢ üìö [Documentation](#-guide-dutilisation) ‚Ä¢ üéØ [Fonctionnalit√©s](#-fonctionnalit√©s-cl√©s) ‚Ä¢ üîß [Installation](#-installation-compl√®te)

---

## üìã TABLE DES MATI√àRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#Ô∏è-architecture-technique)
3. [Stack Technologique](#Ô∏è-stack-technologique)
4. [Fonctionnalit√©s Cl√©s](#-fonctionnalit√©s-cl√©s)
5. [D√©marrage Rapide](#-d√©marrage-rapide)
6. [Installation Compl√®te](#-installation-compl√®te)
7. [Guide d'Utilisation](#-guide-dutilisation)
8. [Qualit√© & Best Practices](#-qualit√©--best-practices)
9. [Roadmap & √âvolutions](#Ô∏è-roadmap--√©volutions)

---

## üéØ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet d√©montre la mise en ≈ìuvre d'une architecture **ETL (Extract, Transform, Load)** automatis√©e pour les syst√®mes d'information logistique et √©nerg√©tique. Il illustre les comp√©tences cl√©s d'un Data Engineer :

‚úÖ **Extraction Multi-Sources :** API simul√©e (JSON) et syst√®mes ERP (CSV).
‚úÖ **Data Transformation :** Nettoyage, jointures et calculs d'agr√©gats complexes via Pandas.
‚úÖ **Mod√©lisation de Donn√©es :** Cr√©ation et chargement dans un Data Warehouse SQL unifi√©.
‚úÖ **Automatisation IT :** Planification Batch nocturne via PowerShell de niveau production.
‚úÖ **Analyses Avanc√©es :** R√©daction de requ√™tes SQL (CTE, Window Functions) pour le pilotage d'activit√©.

### Pourquoi ce projet ?
| Aspect | D√©monstration |
| :--- | :--- |
| **Gouvernance IT** | Consolidation des donn√©es dispers√©es vers une base relationnelle structur√©e. |
| **Scalabilit√©** | Scripts s√©par√©s (`extract.py`, `transform.py`, `load.py`) facilitant l'ajout de nouvelles sources. |
| **Fiabilit√©** | Ex√©cution orchestr√©e (`main_pipeline.py`) supportant la gestion d'exceptions globale. |
| **Business Value** | KPI calcul√©s (Alertes de distribution, Volume par d√©p√¥t) imm√©diatement interpr√©tables en SQL. |

---

## üèóÔ∏è ARCHITECTURE TECHNIQUE

### Diagramme de Flux (Architecture)

```mermaid
graph TB
    subgraph "Data Sources (Extraction)"
        A[üåê API Machines] -->|JSON| C
        B[üè¢ ERP Transactions] -->|CSV| C
    end
    
    subgraph "Data Engineering (Transformation)"
        C[üêç Extract Pandas] --> D[üêç Transform & Clean]
        D -->|Feature Engineering| E[üêç Load SQLAlchemy]
    end
    
    subgraph "Data Warehouse (Stockage & SQL)"
        E -->|DBAPI SQLite| F[(supply_chain_dwh.sqlite)]
        F -->|View / Table| G[fact_transactions]
        F -->|Agr√©gation| H[aggr_daily_site_stats]
    end
    
    subgraph "Automatisation"
        I[‚öôÔ∏è PowerShell Scheduler] -.->|Ex√©cution Nocturne 2:00 AM| C
    end
    
    style A fill:#4A90E2,stroke:#333,stroke-width:2px,color:#fff
    style B fill:#4A90E2,stroke:#333,stroke-width:2px,color:#fff
    style F fill:#50C878,stroke:#333,stroke-width:2px,color:#000
    style I fill:#FFB84D,stroke:#333,stroke-width:2px,color:#000
```

### Explication du Flux

1. **Layer: Extraction** (`extract.py`)
   * Connexion simul√©e au R√©f√©rentiel Machines (API/JSON).
   * R√©cup√©ration des transactions journali√®res Carburant (ERP/CSV).
2. **Layer: Transformation** (`transform.py`)
   * Normalisation des dates (Dates standardis√©es au format `datetime`).
   * Jointure (Merge) des tables de faits et de dimensions.
   * Cr√©ation de variables m√©tiers (Alerte si `volume < 20` ET `status_code IN [WARN, ERR]`).
   * Agr√©gation granulaire (Vue journali√®re par Site Logistique).
3. **Layer: Loading** (`load.py`)
   * Connexion √† SQLite (`supply_chain_dwh.sqlite`) via SQLAlchemy/DBAPI.
   * Ex√©cution du script de d√©finition (DDL) `schema.sql`.
   * Upsert/Replace dans les tables Factuelles et Mats Views.

---

## üõ†Ô∏è STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| :--- | :--- | :--- | :--- |
| **Langage** | Python | 3.12+ | √âcosyst√®me riche pour l'ETL |
| **Moteur SQL** | SQLite3 | - | Base de donn√©es locale l√©g√®re et relationnelle |
| **Traitement** | Pandas | 2.1+ | Outil redoutable pour la transformation de donn√©es tabulaires |
| **Database ORM/Driver**| SQLAlchemy | 2.0+ | Gestion des connexions base de donn√©es en Python |
| **Automatisation** | PowerShell | - | Scripting OS natif pour la Planification de t√¢ches (Task Scheduler) |

---

## üéØ FONCTIONNALIT√âS CL√âS

### üöÄ Fonctionnalit√©s Principales

**1. Orchestration Main**
* Un module principal (`main_pipeline.py`) ex√©cute le workflow et trappe les erreurs critiques pour √©viter les arr√™ts silencieux.

**2. Chargement Dynamique Base SQL**
* Construction √† la vol√©e du sch√©ma et persistance des Dataframes en tables structur√©es.

**3. Analytics SQL de Haut Niveau**
* Fichier `advanced_queries.sql` d√©taillant comment utiliser des fonctions analytiques SQL avanc√©es (LAG, DENSE_RANK, CTE) sur les donn√©es produites par l'ETL.

### üõ°Ô∏è S√©curit√©, Qualit√© & Robustesse
| Aspect | Impl√©mentation |
| :--- | :--- |
| **Automatisation "Hands-Off"**| Script `automate_etl.ps1` branch√© sur le Windows Task Manager. |
| **Validation SQL** | Application d'un sch√©ma strict d√©fini dans `schema.sql` avant tout chargement. |
| **Monitoring** | Utilisation intensive de la biblioth√®que de logs asynchrones `Loguru`. |

---

## üöÄ D√âMARRAGE RAPIDE

### Pr√©requis
```bash
# V√©rifier Python
python --version  # Doit √™tre >= 3.12
```

### Installation Express
```bash
# 1. Naviguer dans le dossier du projet
cd Data-Pipeline-Automation

# 2. Cr√©er un environnement virtuel
python -m venv env
.\env\Scripts\activate

# 3. Installer les d√©pendances (avec prise en compte des versions fixes)
pip install -r requirements.txt

# 4. Ex√©cuter l'orchestrateur
python src/main_pipeline.py
```

---

## üîß INSTALLATION COMPL√àTE
Suivez l'installation expresse. L'environnement virtuel garanti la s√©curit√© d'isolation du projet tout en assurant avec stricte compatibilit√© la balance `Pandas` / `Numpy`.

---

## üìñ GUIDE D'UTILISATION

### Analyse en Base de Donn√©es
Une fois les donn√©es charg√©es via l'ETL, le fichier `database/supply_chain_dwh.sqlite` est g√©n√©r√©.
Vous pouvez utiliser un outil (ex: DBeaver, SQLite Studio) pour lancer le script `sql/advanced_queries.sql` qui d√©montre des corr√©lations complexes sur vos sites.

### Activer l'Automatisation Serveur (Windows)
Pour programmer le job Python afin qu'il s'ex√©cute silencieusement toutes les nuits √† 2:00 AM :
1. Ouvrez un terminal **PowerShell en tant qu'Administrateur**.
2. Ex√©cutez :
```powershell
.\automate_etl.ps1
```

### üì∏ Capture d'√âcran
![R√©sultat de l'ex√©cution en Console](./resultat.png)

---

## ‚ú® QUALIT√â & BEST PRACTICES

### Principes Appliqu√©s
| Principe | Impl√©mentation |
| :--- | :--- |
| **ETL D√©coupl√©** | Code distribu√© de fa√ßon logique pour tester la transformation sans taper dans la Prod. |
| **R√©silience d'Environnement** | Fichier requirements.txt strict (`numpy==1.26.0`) pour √©viter les "breaking changes". |
| **Code Auto-Document√©** | Variables et fonctions (`df_machines`, `df_transactions`) m√©tier explicites. |

---

## üó∫Ô∏è ROADMAP & √âVOLUTIONS

**Version Actuelle : 1.0.0** ‚úÖ
* [x] Pipeline EXTRACT, TRANSFORM, LOAD complet
* [x] SQL Engine param√©tr√©
* [x] Automatisation de Batch OS int√©gr√©e

**Version 1.1.0 (Prochaine Release)** üöß
* Passage de SQLite vers un Data Warehouse Cloud (Snowflake/BigQuery).
* Dockerisation de l'ETL.

---

## üìÑ LICENCE
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

## üë®‚Äçüíª AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
*Ing√©nieur Logiciel & Data | √âtudiant ESIEA*

üìß Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
üíº LinkedIn : [Votre profil LinkedIn]  
üêô GitHub : @Lkb-2905  

## üôè REMERCIEMENTS
* **Pandas Community :** Pour la biblioth√®que de Data Engineering par excellence.
* **SQLAlchemy :** Pour avoir r√©volutionn√© la fa√ßon de parler aux bases SQL.

‚≠ê Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile !  
Fait avec ‚ù§Ô∏è et Python

¬© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits r√©serv√©s
